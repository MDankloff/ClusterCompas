{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMolzf1Ji8eXUdIHCX/Dzox",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MDankloff/ClusterCompas/blob/main/Kmeans_Bafv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "1PdnCtzI9weo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um3esJVD9GFd",
        "outputId": "1a845488-8ef5-4979-c550-f6c547342b0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "! cd '/content/drive/MyDrive/Mirthe_Supervision /Paper#2/Colab Notebooks'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import random\n",
        "import os\n",
        "import math\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import chi2_contingency\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "from scipy import stats\n",
        "from scipy.stats import ttest_ind\n",
        "from scipy.stats import f_oneway\n",
        "from google.colab import files\n",
        "import re\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "9Z4rfAWL90G_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UTILS"
      ],
      "metadata": {
        "id": "tTn_RgT8-DRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set of Features (aka data columns)"
      ],
      "metadata": {
        "id": "dahEhY_--FiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Master dataset\n",
        "#FEATURES\n",
        "META = ['clusters', 'new_clusters']\n",
        "ERROR = ['errors', 'TP', 'TN', 'FN', 'FP']\n",
        "REG = ['bank_branch_count_8w',\n",
        "       #'credit_risk_score',\n",
        "       'device_os','month', 'session_length_in_minutes', 'email_is_free',\n",
        "       'proposed_credit_limit',\n",
        "       'name_email_similarity',\n",
        "      'zip_count_4w', 'date_of_birth_distinct_emails_4w', 'phone_mobile_valid', 'has_other_cards', 'foreign_request']\n",
        "SEN = ['customer_age', 'income'] #protected attributes in BAF paper also employment_status\n",
        "DUMMY = ['source_INTERNET', 'Source_TELEAPP', 'device_os_other', 'device_os_macintosh','device_os_linux','device_os_windows', 'device_os_x11']\n",
        "\n",
        "#FEATURES SCALED\n",
        "ERROR_scaled = ['errors_scaled']\n",
        "REG_scaled = ['bank_branch_count_8w_scaled',\n",
        "              #'credit_risk_score_scaled',\n",
        "              'device_os_scaled','month_scaled', 'session_length_in_minutes_scaled',\n",
        "              'email_is_free_scaled',\n",
        "              'proposed_credit_limit_scaled',\n",
        "              'name_email_similarity_scaled',\n",
        "              'zip_count_4w_scaled',\n",
        "              'date_of_birth_distinct_emails_4w_scaled', 'phone_home_valid_scaled','has_other_cards_scaled', 'foreign_request_scaled']\n",
        "SEN_scaled = ['customer_age_scaled', 'income_scaled']\n",
        "DUMMY_scaled = ['source_INTERNET_scaled', 'Source_TELEAPP_scaled', 'device_os_other_scaled', 'device_os_macintosh_scaled', 'device_os_linux_scaled', 'device_os_windows_scaled', 'device_os_x11_scaled']\n",
        "\n",
        "\n",
        "#SHAP FEATURES\n",
        "SHAP_REG = ['bank_branch_count_8w_shap',\n",
        "            #'credit_risk_score_shap',\n",
        "            'device_os_shap', 'month_shap', 'session_length_in_minutes_shap', 'email_is_free_shap', 'proposed_credit_limit_shap', 'name_email_similarity_shap',\n",
        " 'zip_count_4w_shap', 'date_of_birth_distinct_emails_4w_shap', 'phone_mobile_valid_shap', 'has_other_cards_shap', 'foreign_request_shap']\n",
        "SHAP_SEN = ['customer_age_shap', 'income_shap']\n",
        "SHAP_DUMMY = ['source_INTERNET_shap', 'Source_TELEAPP_shap', 'device_os_other_shap', 'device_os_macintosh_shap','device_os_linux_shap','device_os_windows_shap', 'device_os_x11_shap']\n",
        "\n",
        "#SHAP FEATURES SCALED\n",
        "SHAP_REG_scaled = ['bank_branch_count_8w_shap_scaled',\n",
        "                   #'credit_risk_score_shap_scaled',\n",
        "                   'device_os_shap_scaled', 'month_shap_scaled', 'session_length_in_minutes_shap_scaled',\n",
        " 'email_is_free_shap_scaled', 'proposed_credit_limit_shap_scaled', 'name_email_similarity_shap_scaled', 'zip_count_4w_shap_scaled',\n",
        " 'date_of_birth_distinct_emails_4w_shap_scaled', 'phone_mobile_valid_shap_scaled', 'has_other_cards_shap_scaled', 'foreign_request_shap_scaled']\n",
        "SHAP_SEN_scaled = ['customer_age_shap_scaled', 'income_shap_scaled']\n",
        "SHAP_DUMMY_scaled = ['source_INTERNET_shap_scaled', 'Source_TELEAPP_shap_scaled', 'device_os_other_shap_scaled', 'device_os_macintosh_shap_scaled',\n",
        " 'device_os_linux_shap_scaled', 'device_os_windows_shap_scaled', 'device_os_x11_shap_scaled']\n",
        "\n",
        "'''removed features = 'device_fraud_count', 'intended_balcon_amount', 'payment_type', 'days_since_request',\n",
        "'velocity_6h', 'velocity_24h', 'velocity_4w', 'keep_alive_session', 'prev_address_months_count', 'current_address_months_count', 'phone_home_valid', 'bank_months_count', 'device_distinct_emails_8w', 'housing_status', 'employment_status' '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "bBZBBmk8-JQ2",
        "outputId": "781e87f7-45e5-442d-d1d2-8a7f301e0a0c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"removed features = 'device_fraud_count', 'intended_balcon_amount', 'payment_type', 'days_since_request',\\n'velocity_6h', 'velocity_24h', 'velocity_4w', 'keep_alive_session', 'prev_address_months_count', 'current_address_months_count', 'phone_home_valid', 'bank_months_count', 'device_distinct_emails_8w', 'housing_status', 'employment_status' \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils for Data prep"
      ],
      "metadata": {
        "id": "MrCFVWz4CMiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Seperate TPFN & TNFP dataset\n",
        "'''Drop rows where both TP and FN are 0 '''\n",
        "def subset_TP_FN(data):\n",
        "    return data.loc[(data['TP'] == 1) | (data['FN'] == 1)]\n",
        "\n",
        "'''Drop rows where both TN and FP are 0'''\n",
        "def subset_TN_FP(data):\n",
        "    return data.loc[(data['TN'] == 1) | (data['FP'] == 1)]\n",
        "\n",
        "'''undo Dummy for DUMMY_source or DUMMY_device'''\n",
        "def undo_dummy(data, with_Dummy, col_label, numeric_values=True, short_label=None):\n",
        "  data[col_label] = ''\n",
        "  for i, c in enumerate(with_Dummy):\n",
        "    values = np.sort(data[c].unique())\n",
        "    if numeric_values:\n",
        "      data.loc[data[c] == values[1], col_label] = i\n",
        "    else:\n",
        "      if short_label is None:\n",
        "        raise ValueError(\"short label must be provided if numeric_values is False\")\n",
        "        data.loc[data[c] == values[1], col_label] = short_label[i]\n",
        "    data = data.drop(c, axis=1)\n",
        "  return(data)\n",
        "\n",
        "#data = undo_dummy(data, DUMMY_RACE, col_label='race', numeric_values=False, short_label=SHORT_LABEL_RACE)\n",
        "#data = undo_dummy(data, DUMMY_GENDER, col_label='gender', numeric_values=False, short_label=SHORT_LABEL_GENDER)\n",
        ""
      ],
      "metadata": {
        "id": "duYEXRK8COmm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils for Clustering"
      ],
      "metadata": {
        "id": "FTFOkvQ1Cp8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate average (unscaled) Error rate by counting the amount of max values (1) and dividing them by the total nr of rows\n",
        "# Does not work on scaled (binary) error features\n",
        "def get_error_rate(data, column='errors'):\n",
        "  if len(data) == 0:\n",
        "    print ('calculating error rate on an empty set')\n",
        "    return\n",
        "  max_value = data[column].max()\n",
        "  count_max_value = (data[column] == max_value).sum()\n",
        "  average_error_rate = count_max_value / len(data)\n",
        "  return average_error_rate\n",
        "\n",
        "\n",
        "def get_next_cluster(data, cluster_col, min_size, all_cluster_ids, banned_clusters):\n",
        "  if(len(banned_clusters) != 0):\n",
        "    filter_tf = np.isin(all_cluster_ids, banned_clusters, invert=True)\n",
        "    all_cluster_ids = all_cluster_ids[filter_tf]\n",
        "\n",
        "  for candidate_cluster_id in all_cluster_ids:\n",
        "    if candidate_cluster_id == -1:\n",
        "      continue\n",
        "\n",
        "    #print ('This is the next cluster:', candidate_cluster_id)\n",
        "\n",
        "    candidate_cluster = data.loc[data[cluster_col] == candidate_cluster_id]\n",
        "\n",
        "    if len(candidate_cluster) < min_size:\n",
        "      #print('...it is too small:', len(candidate_cluster))\n",
        "      continue\n",
        "    else:\n",
        "      return(candidate_cluster_id)\n",
        "\n",
        "  #print('No suitable clusters were found!')\n",
        "  return(-1)\n",
        ""
      ],
      "metadata": {
        "id": "yx91KNqYCnXD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils for Results"
      ],
      "metadata": {
        "id": "1Q4IY7w8DXMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "make recap"
      ],
      "metadata": {
        "id": "_CnlAGCQDb16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_recap(data_result, feature_set):\n",
        "    # Make recap of cluster info with error rates\n",
        "    res = data_result[['clusters', 'errors']]\n",
        "\n",
        "    # Cluster size\n",
        "    temp = data_result[['clusters']]\n",
        "    temp['count'] = 1\n",
        "    recap = temp.groupby(['clusters'], as_index=False).sum()\n",
        "\n",
        "    # Number of errors\n",
        "    recap['n_error'] = res.groupby(['clusters']).sum().astype(int)\n",
        "\n",
        "    # Error rate calculation\n",
        "    recap['error_rate'] = res.groupby(['clusters']).mean()\n",
        "\n",
        "    # Quality metrics preparation\n",
        "    diff_vs_rest = []\n",
        "    diff_p = []\n",
        "\n",
        "    age_prop = []\n",
        "    age_diff = []\n",
        "    age_p = []\n",
        "\n",
        "    income_prop = []\n",
        "    income_diff = []\n",
        "    income_p = []\n",
        "\n",
        "    silhouette = []\n",
        "\n",
        "    # Calculate silhouette scores\n",
        "    clusters = data_result['clusters']\n",
        "    if len(recap['clusters'].unique()) > 1:\n",
        "        silhouette_val = silhouette_samples(data_result[feature_set], clusters)\n",
        "\n",
        "    for c in recap['clusters']:\n",
        "        # In-cluster data\n",
        "        c_data = data_result.loc[data_result['clusters'] == c]\n",
        "        c_count = recap['count'][c]\n",
        "\n",
        "        # Out-of-cluster data\n",
        "        rest_data = data_result.loc[data_result['clusters'] != c]\n",
        "        if len(rest_data) == 0:\n",
        "            diff_vs_rest.extend([np.nan] * 2)\n",
        "            age_prop.extend([np.nan] * 3)\n",
        "            income_prop.extend([np.nan] * 3)\n",
        "            silhouette.append(np.nan)\n",
        "            continue\n",
        "\n",
        "        # Add silhouette score\n",
        "        silhouette.append(silhouette_val[clusters == c].mean())\n",
        "\n",
        "        rest_recap = recap.loc[recap['clusters'] != c]\n",
        "        rest_count = rest_recap['count'].sum()\n",
        "\n",
        "        # Error rate difference\n",
        "        rest_n_error = rest_recap['n_error'].sum()\n",
        "        rest_rate = rest_n_error / rest_count\n",
        "        diff_vs_rest.append(recap['error_rate'][c] - rest_rate)\n",
        "\n",
        "        # Poisson stat test for errors\n",
        "        if any(x < 1 for x in [recap['n_error'][c], recap['count'][c], rest_n_error, rest_count]):\n",
        "            res = stats.poisson_means_test(recap['count'][c] - recap['n_error'][c], recap['count'][c],\n",
        "                                           rest_count - rest_n_error, rest_count)\n",
        "        else:\n",
        "            res = stats.poisson_means_test(recap['n_error'][c], recap['count'][c], rest_n_error, rest_count)\n",
        "        diff_p.append(round(res.pvalue, 3))\n",
        "\n",
        "        #### Sensitive features (age, income)\n",
        "        # Age feature (customer_age)\n",
        "        rest_n_age = rest_data['customer_age'].sum()\n",
        "        rest_prop_age = rest_n_age / rest_count\n",
        "        c_n_age = c_data['customer_age'].sum()\n",
        "        c_prop_age = c_n_age / c_count\n",
        "\n",
        "        age_prop.append(c_prop_age)\n",
        "        age_diff.append(c_prop_age - rest_prop_age)\n",
        "\n",
        "        if any(x < 1 for x in [c_n_age, c_count, rest_n_age, rest_count]):\n",
        "            res = stats.poisson_means_test(c_count - c_n_age, c_count, rest_count - rest_n_age, rest_count)\n",
        "        else:\n",
        "            res = stats.poisson_means_test(c_n_age, c_count, rest_n_age, rest_count)\n",
        "        age_p.append(round(res.pvalue, 3))\n",
        "\n",
        "        # Income feature (income)\n",
        "        rest_n_income = rest_data['income'].sum()\n",
        "        rest_prop_income = rest_n_income / rest_count\n",
        "        c_n_income = c_data['income'].sum()\n",
        "        c_prop_income = c_n_income / c_count\n",
        "\n",
        "        income_prop.append(c_prop_income)\n",
        "        income_diff.append(c_prop_income - rest_prop_income)\n",
        "\n",
        "        if any(x < 1 for x in [c_n_income, c_count, rest_n_income, rest_count]):\n",
        "            res = stats.poisson_means_test(c_count - c_n_income, c_count, rest_count - rest_n_income, rest_count)\n",
        "        else:\n",
        "            res = stats.poisson_means_test(c_n_income, c_count, rest_n_income, rest_count)\n",
        "        income_p.append(round(res.pvalue, 3))\n",
        "\n",
        "    # Populate recap DataFrame with results\n",
        "    recap['diff_vs_rest'] = np.around(diff_vs_rest, 3)\n",
        "    recap['diff_p'] = diff_p\n",
        "    recap['age_prop'] = np.around(age_prop, 3)\n",
        "    recap['age_diff'] = np.around(age_diff, 3)\n",
        "    recap['age_p'] = age_p\n",
        "    recap['income_prop'] = np.around(income_prop, 3)\n",
        "    recap['income_diff'] = np.around(income_diff, 3)\n",
        "    recap['income_p'] = income_p\n",
        "    recap['silhouette'] = silhouette\n",
        "    recap['error_rate'] = np.around(recap['error_rate'], 3)\n",
        "\n",
        "    # Rename columns for clarity\n",
        "    recap.rename(columns={'clusters': 'c'}, inplace=True)\n",
        "\n",
        "    return recap\n",
        "\n",
        "'''def make_recap(data_result, feature_set):\n",
        "  # MAKE RECAP of cluster info\n",
        "  # ...with error rates\n",
        "  res = data_result[['clusters', 'errors']]\n",
        "\n",
        "  # ...with cluster size\n",
        "  temp = data_result[['clusters']]\n",
        "  temp['count'] = 1\n",
        "  recap = temp.groupby(['clusters'], as_index=False).sum()\n",
        "\n",
        "  # ...with number of error\n",
        "  recap['n_error'] = res.groupby(['clusters']).sum().astype(int)\n",
        "\n",
        "  # ...with 1-vs-All error diff\n",
        "  recap['error_rate'] = res.groupby(['clusters']).mean()\n",
        "  # recap['std'] = (recap['error_rate'] * (1-recap['error_rate']))/recap['count']\n",
        "  # recap['std'] = recap['std'].apply(np.sqrt)\n",
        "\n",
        "  # Prepare Quality metrics\n",
        "  diff_vs_rest = []\n",
        "  # diff_std = []\n",
        "  diff_p =[]\n",
        "\n",
        "  age_prop = []\n",
        "  age_diff = []\n",
        "  age_p = []\n",
        "\n",
        "  income_prop = []\n",
        "  income_diff = []\n",
        "  income_p = []\n",
        "\n",
        "  silhouette = []\n",
        "\n",
        "  # Get individual silhouette scores\n",
        "  clusters = data_result['clusters']\n",
        "  if(len(recap['clusters'].unique()) > 1):\n",
        "    silhouette_val = silhouette_samples(data_result[feature_set], clusters)\n",
        "\n",
        "  for c in recap['clusters']:\n",
        "    # Get in-cluster data\n",
        "    c_data = data_result.loc[data_result['clusters'] == c]\n",
        "    c_count = recap['count'][c]\n",
        "\n",
        "    # Get out-of-cluster data\n",
        "    rest_data = data_result.loc[data_result['clusters'] != c]\n",
        "    # Check if no other cluster\n",
        "    if(len(rest_data) == 0):\n",
        "      diff_vs_rest.append(np.nan)\n",
        "      # diff_std.append(np.nan)\n",
        "      diff_p.append(np.nan)\n",
        "\n",
        "      age.append(np.nan)\n",
        "      age.append(np.nan)\n",
        "      age.append(np.nan)\n",
        "\n",
        "      #race_c_prop.append(np.nan)\n",
        "      #race_c_diff.append(np.nan)\n",
        "      #race_c_p.append(np.nan)\n",
        "\n",
        "      income.append(np.nan)\n",
        "      income.append(np.nan)\n",
        "      income.append(np.nan)\n",
        "\n",
        "      silhouette.append(np.nan)\n",
        "      break\n",
        "\n",
        "    # Add silhouette score\n",
        "    silhouette.append(silhouette_val[clusters == c].mean())\n",
        "\n",
        "    rest_recap = recap.loc[recap['clusters'] != c]\n",
        "    rest_count = rest_recap['count'].sum()\n",
        "\n",
        "    #### Quick test: differences in error rates\n",
        "    # Get error rate difference 1-vs-rest\n",
        "    rest_n_error = rest_recap['n_error'].sum()\n",
        "    rest_rate = rest_n_error / rest_count\n",
        "    diff_vs_rest.append(recap['error_rate'][c] - rest_rate)\n",
        "\n",
        "    # ...with std deviation of error differences\n",
        "    # std_rest = (rest_rate * (1-rest_rate))/rest_count\n",
        "    # std_rest = np.sqrt(std_rest)\n",
        "    # diff_std.append(recap['std'][c] + std_rest)\n",
        "\n",
        "    # ...with Poisson stat testprint('Zero!')\n",
        "    # Deal with splits with 0 error (by using either number of errors (FN or FP), or number of correct classifications (TP or TN))\n",
        "    if((recap['n_error'][c] < 1) | (recap['count'][c] < 1) | (rest_n_error < 1) | (rest_count < 1)):\n",
        "      res = stats.poisson_means_test(recap['count'][c] - recap['n_error'][c], recap['count'][c], rest_count - rest_n_error, rest_count)\n",
        "      diff_p.append(round(res.pvalue, 3))\n",
        "    else:\n",
        "      res = stats.poisson_means_test(recap['n_error'][c], recap['count'][c], rest_n_error, rest_count)\n",
        "      diff_p.append(round(res.pvalue, 3))\n",
        "\n",
        "    ##### Sensitive features (age, income) --\n",
        "    ### Age feature (customer_age)\n",
        "    rest_n_age = rest_data['customer_age'].sum()\n",
        "    rest_prop_age = rest_n_age / rest_count\n",
        "    c_n_age = c_data['customer_age'].sum()\n",
        "    c_prop_age = c_n_age / c_count\n",
        "\n",
        "    age_prop.append(c_prop_age)\n",
        "    age_diff.append(c_prop_age - rest_prop_age)\n",
        "\n",
        "    if any(x < 1 for x in [c_n_age, c_count, rest_n_age, rest_count]):\n",
        "        res = stats.poisson_means_test(c_count - c_n_age, c_count, rest_count - rest_n_age, rest_count)\n",
        "    else:\n",
        "        res = stats.poisson_means_test(c_n_age, c_count, rest_n_age, rest_count)\n",
        "    age_p.append(round(res.pvalue, 3))\n",
        "\n",
        "    ### Income feature (Income)\n",
        "    rest_n_c = rest_data['race_Caucasian'].sum()\n",
        "    rest_prop_c = rest_n_c / rest_count\n",
        "\n",
        "    c_n_c = c_data['race_Caucasian'].sum()\n",
        "    c_prop_c = c_n_c / c_count\n",
        "\n",
        "    race_c_prop.append(c_prop_c)\n",
        "    race_c_diff.append(c_prop_c - rest_prop_c)\n",
        "\n",
        "    # Deal with splits with 0 African-American (by using either number of AA, or number of non-AA)\n",
        "    if((c_n_c < 1) | (c_count < 1) | (rest_n_c < 1) | (rest_count < 1)):\n",
        "      res = stats.poisson_means_test(c_count - c_n_c, c_count, rest_count - rest_n_c, rest_count)\n",
        "      race_c_p.append(round(res.pvalue, 3))\n",
        "    else:\n",
        "      res = stats.poisson_means_test(c_n_c, c_count, rest_n_c, rest_count)\n",
        "      race_c_p.append(round(res.pvalue, 3))\n",
        "\n",
        "    ##### Gender\n",
        "    rest_n_female = rest_data['sex_Female'].sum()\n",
        "    rest_prop_female = rest_n_female/ rest_count\n",
        "\n",
        "    c_n_female = c_data['sex_Female'].sum()\n",
        "    c_prop_female = c_n_female / c_count\n",
        "\n",
        "    female_prop.append(c_prop_female)\n",
        "    female_diff.append(c_prop_female - rest_prop_female)\n",
        "\n",
        "    # Deal with splits with 0 females(by using either number of females, or number of males)\n",
        "    if((c_n_female < 1) | (c_count < 1) | (rest_n_female < 1) | (rest_count < 1)):\n",
        "      res = stats.poisson_means_test(c_count - c_n_female, c_count, rest_count - rest_n_female, rest_count)\n",
        "      female_p.append(round(res.pvalue, 3))\n",
        "    else:\n",
        "      res = stats.poisson_means_test(c_n_female, c_count, rest_n_female, rest_count)\n",
        "      female_p.append(round(res.pvalue, 3))\n",
        "\n",
        "  recap['diff_vs_rest'] = np.around(diff_vs_rest, 3)\n",
        "  # recap['diff_std'] = np.around(diff_std, 3)\n",
        "  recap['diff_p'] = diff_p\n",
        "\n",
        "  recap['race_aa_prop'] = np.around(race_aa_prop, 3)\n",
        "  recap['race_aa_diff'] = np.around(race_aa_diff, 3)\n",
        "  recap['race_aa_p'] = race_aa_p\n",
        "\n",
        "  recap['race_c_prop'] = np.around(race_c_prop, 3)\n",
        "  recap['race_c_diff'] = np.around(race_c_diff, 3)\n",
        "  recap['race_c_p'] = race_c_p\n",
        "\n",
        "  recap['female_prop'] = np.around(female_prop, 3)\n",
        "  recap['female_diff'] = np.around(female_diff, 3)\n",
        "  recap['female_p'] = female_p\n",
        "\n",
        "  recap['silhouette'] = silhouette\n",
        "\n",
        "  recap['error_rate'] = np.around(recap['error_rate'] , 3)\n",
        "  # recap['std'] = np.around(recap['std'] , 3)\n",
        "\n",
        "  recap.rename(columns={'clusters':'c'}, inplace=True)\n",
        "  #print(recap.sort_values(by=['diff_p']))\n",
        "\n",
        "  return(recap)'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "fUzX1WJpDZx-",
        "outputId": "d90e2011-1ec0-4613-96a1-fcd9b3f3342c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"def make_recap(data_result, feature_set):\\n  # MAKE RECAP of cluster info\\n  # ...with error rates\\n  res = data_result[['clusters', 'errors']]\\n\\n  # ...with cluster size\\n  temp = data_result[['clusters']]\\n  temp['count'] = 1\\n  recap = temp.groupby(['clusters'], as_index=False).sum()\\n\\n  # ...with number of error\\n  recap['n_error'] = res.groupby(['clusters']).sum().astype(int)\\n\\n  # ...with 1-vs-All error diff\\n  recap['error_rate'] = res.groupby(['clusters']).mean()\\n  # recap['std'] = (recap['error_rate'] * (1-recap['error_rate']))/recap['count']\\n  # recap['std'] = recap['std'].apply(np.sqrt)\\n\\n  # Prepare Quality metrics\\n  diff_vs_rest = []\\n  # diff_std = []\\n  diff_p =[]\\n\\n  age_prop = []\\n  age_diff = []\\n  age_p = []\\n\\n  income_prop = []\\n  income_diff = []\\n  income_p = []\\n\\n  silhouette = []\\n\\n  # Get individual silhouette scores\\n  clusters = data_result['clusters']\\n  if(len(recap['clusters'].unique()) > 1):\\n    silhouette_val = silhouette_samples(data_result[feature_set], clusters)\\n\\n  for c in recap['clusters']:\\n    # Get in-cluster data\\n    c_data = data_result.loc[data_result['clusters'] == c]\\n    c_count = recap['count'][c]\\n\\n    # Get out-of-cluster data\\n    rest_data = data_result.loc[data_result['clusters'] != c]\\n    # Check if no other cluster\\n    if(len(rest_data) == 0):\\n      diff_vs_rest.append(np.nan)\\n      # diff_std.append(np.nan)\\n      diff_p.append(np.nan)\\n\\n      age.append(np.nan)\\n      age.append(np.nan)\\n      age.append(np.nan)\\n\\n      #race_c_prop.append(np.nan)\\n      #race_c_diff.append(np.nan)\\n      #race_c_p.append(np.nan)\\n\\n      income.append(np.nan)\\n      income.append(np.nan)\\n      income.append(np.nan)\\n\\n      silhouette.append(np.nan)\\n      break\\n\\n    # Add silhouette score\\n    silhouette.append(silhouette_val[clusters == c].mean())\\n\\n    rest_recap = recap.loc[recap['clusters'] != c]\\n    rest_count = rest_recap['count'].sum()\\n\\n    #### Quick test: differences in error rates\\n    # Get error rate difference 1-vs-rest\\n    rest_n_error = rest_recap['n_error'].sum()\\n    rest_rate = rest_n_error / rest_count\\n    diff_vs_rest.append(recap['error_rate'][c] - rest_rate)\\n\\n    # ...with std deviation of error differences\\n    # std_rest = (rest_rate * (1-rest_rate))/rest_count\\n    # std_rest = np.sqrt(std_rest)\\n    # diff_std.append(recap['std'][c] + std_rest)\\n\\n    # ...with Poisson stat testprint('Zero!')\\n    # Deal with splits with 0 error (by using either number of errors (FN or FP), or number of correct classifications (TP or TN))\\n    if((recap['n_error'][c] < 1) | (recap['count'][c] < 1) | (rest_n_error < 1) | (rest_count < 1)):\\n      res = stats.poisson_means_test(recap['count'][c] - recap['n_error'][c], recap['count'][c], rest_count - rest_n_error, rest_count)\\n      diff_p.append(round(res.pvalue, 3))\\n    else:\\n      res = stats.poisson_means_test(recap['n_error'][c], recap['count'][c], rest_n_error, rest_count)\\n      diff_p.append(round(res.pvalue, 3))\\n\\n    ##### Sensitive features (age, income) -- \\n    ### Age feature (customer_age)\\n    rest_n_age = rest_data['customer_age'].sum()\\n    rest_prop_age = rest_n_age / rest_count\\n    c_n_age = c_data['customer_age'].sum()\\n    c_prop_age = c_n_age / c_count\\n\\n    age_prop.append(c_prop_age)\\n    age_diff.append(c_prop_age - rest_prop_age)\\n\\n    if any(x < 1 for x in [c_n_age, c_count, rest_n_age, rest_count]):\\n        res = stats.poisson_means_test(c_count - c_n_age, c_count, rest_count - rest_n_age, rest_count)\\n    else:\\n        res = stats.poisson_means_test(c_n_age, c_count, rest_n_age, rest_count)\\n    age_p.append(round(res.pvalue, 3))\\n\\n    ### Income feature (Income) \\n    rest_n_c = rest_data['race_Caucasian'].sum()\\n    rest_prop_c = rest_n_c / rest_count\\n\\n    c_n_c = c_data['race_Caucasian'].sum()\\n    c_prop_c = c_n_c / c_count\\n\\n    race_c_prop.append(c_prop_c)\\n    race_c_diff.append(c_prop_c - rest_prop_c)\\n\\n    # Deal with splits with 0 African-American (by using either number of AA, or number of non-AA)\\n    if((c_n_c < 1) | (c_count < 1) | (rest_n_c < 1) | (rest_count < 1)):\\n      res = stats.poisson_means_test(c_count - c_n_c, c_count, rest_count - rest_n_c, rest_count)\\n      race_c_p.append(round(res.pvalue, 3))\\n    else:\\n      res = stats.poisson_means_test(c_n_c, c_count, rest_n_c, rest_count)\\n      race_c_p.append(round(res.pvalue, 3))\\n\\n    ##### Gender\\n    rest_n_female = rest_data['sex_Female'].sum()\\n    rest_prop_female = rest_n_female/ rest_count\\n\\n    c_n_female = c_data['sex_Female'].sum()\\n    c_prop_female = c_n_female / c_count\\n\\n    female_prop.append(c_prop_female)\\n    female_diff.append(c_prop_female - rest_prop_female)\\n\\n    # Deal with splits with 0 females(by using either number of females, or number of males)\\n    if((c_n_female < 1) | (c_count < 1) | (rest_n_female < 1) | (rest_count < 1)):\\n      res = stats.poisson_means_test(c_count - c_n_female, c_count, rest_count - rest_n_female, rest_count)\\n      female_p.append(round(res.pvalue, 3))\\n    else:\\n      res = stats.poisson_means_test(c_n_female, c_count, rest_n_female, rest_count)\\n      female_p.append(round(res.pvalue, 3))\\n\\n  recap['diff_vs_rest'] = np.around(diff_vs_rest, 3)\\n  # recap['diff_std'] = np.around(diff_std, 3)\\n  recap['diff_p'] = diff_p\\n\\n  recap['race_aa_prop'] = np.around(race_aa_prop, 3)\\n  recap['race_aa_diff'] = np.around(race_aa_diff, 3)\\n  recap['race_aa_p'] = race_aa_p\\n\\n  recap['race_c_prop'] = np.around(race_c_prop, 3)\\n  recap['race_c_diff'] = np.around(race_c_diff, 3)\\n  recap['race_c_p'] = race_c_p\\n\\n  recap['female_prop'] = np.around(female_prop, 3)\\n  recap['female_diff'] = np.around(female_diff, 3)\\n  recap['female_p'] = female_p\\n\\n  recap['silhouette'] = silhouette\\n\\n  recap['error_rate'] = np.around(recap['error_rate'] , 3)\\n  # recap['std'] = np.around(recap['std'] , 3)\\n\\n  recap.rename(columns={'clusters':'c'}, inplace=True)\\n  #print(recap.sort_values(by=['diff_p']))\\n\\n  return(recap)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chi-Square Tests"
      ],
      "metadata": {
        "id": "E8eom7jtHfqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_chi_tests(results):\n",
        "  chi_res = {'cond_descr': [],\n",
        "            'cond_name': [],\n",
        "            'error': [],\n",
        "            'age': [],\n",
        "            'income': []}\n",
        "\n",
        "  for i in range(0, len(results['cond_name'])):\n",
        "    chi_res['cond_descr'].append(results['cond_descr'][i])\n",
        "    chi_res['cond_name'].append(results['cond_name'][i])\n",
        "    data = results['cond_res'][i]\n",
        "    recap = results['cond_recap'][i]\n",
        "\n",
        "    if(len(recap['diff_p']) == 1):\n",
        "      chi_res['error'].append(np.nan)\n",
        "      chi_res['age'].append(np.nan)\n",
        "      chi_res['income'].append(np.nan)\n",
        "      continue\n",
        "\n",
        "    # Test error differences\n",
        "    test_data = recap[['count', 'n_error']].copy(deep=True)\n",
        "\n",
        "    test_data['count'] = test_data['count'] - test_data['n_error']\n",
        "    test_data = test_data.rename(columns={\"count\": \"n_correct\"})\n",
        "\n",
        "    test_data = test_data.transpose()\n",
        "    test_res = chi2_contingency(test_data)\n",
        "    chi_res['error'].append(round(test_res.pvalue, 6))\n",
        "\n",
        "    #print(test_data)\n",
        "    # print(round(test_res.pvalue, 6))\n",
        "\n",
        "    # Test income differences\n",
        "    test_data = recap[['count', 'income_prop']].copy(deep=True)\n",
        "\n",
        "    test_data['income_prop'] = round(test_data['count'] * test_data['income_prop'])\n",
        "    test_data = test_data.rename(columns={\"income_prop\": \"income_n\"}).astype(int)\n",
        "\n",
        "    test_data['count'] = test_data['count'] - test_data['income_n']\n",
        "    test_data = test_data.rename(columns={\"count\": \"income_n\"})\n",
        "\n",
        "    test_data = test_data.transpose()\n",
        "    test_res = chi2_contingency(test_data)\n",
        "    chi_res['income'].append(round(test_res.pvalue, 6))\n",
        "\n",
        "    # print(test_data)\n",
        "    # print(round(test_res.pvalue, 6))\n",
        "\n",
        "    # Test age differences\n",
        "    test_data = recap[['count', 'age_prop']].copy(deep=True)\n",
        "\n",
        "    test_data['age_prop'] = round(test_data['count'] * test_data['age_prop'])\n",
        "    test_data = test_data.rename(columns={\"age_prop\": \"age_n\"}).astype(int)\n",
        "\n",
        "    test_data['count'] = test_data['count'] - test_data['age_n']\n",
        "    test_data = test_data.rename(columns={\"count\": \"age_n\"})\n",
        "\n",
        "    test_data = test_data.transpose()\n",
        "    test_res = chi2_contingency(test_data)\n",
        "    chi_res['age'].append(round(test_res.pvalue, 6))\n",
        "\n",
        "  return(pd.DataFrame(chi_res))\n",
        ""
      ],
      "metadata": {
        "id": "sTsR15R6HQfJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All Quality Metrics"
      ],
      "metadata": {
        "id": "_NypSKY8OM_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recap_quali_metrics(chi_res, results, exp_condition):\n",
        "  all_quali = {'cond_descr': chi_res['cond_descr'],\n",
        "            'cond_name': chi_res['cond_name'],\n",
        "            'error': chi_res['error'],\n",
        "            'age': chi_res['age'],\n",
        "            'income': chi_res['income'],\n",
        "            'silhouette': []}\n",
        "\n",
        "  for i in range(0, len(chi_res['cond_name'])):\n",
        "    data = results['cond_res'][i]\n",
        "    feature_set = exp_condition['feature_set'][i]\n",
        "    clusters = data['clusters']\n",
        "    recap = results['cond_recap'][i]\n",
        "    if(len(recap['diff_p']) == 1):\n",
        "      all_quali['silhouette'].append(np.nan)\n",
        "      continue\n",
        "    silhouette_indiv = silhouette_samples(data[feature_set], clusters)\n",
        "    silhouette_avg = silhouette_indiv.mean()\n",
        "    all_quali['silhouette'].append(silhouette_avg)\n",
        "\n",
        "  return(pd.DataFrame(all_quali))"
      ],
      "metadata": {
        "id": "IQefKTk3OQEV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils for VIZ"
      ],
      "metadata": {
        "id": "T4DB7lr6Op6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tsne_plot_wClusters(data, title, perplexity, learning_rate, n_iter, alpha, size, tsne_columns, fig_prefix):\n",
        "  # Extract features for t-SNE and drop other_columns\n",
        "  tsne_features = data[tsne_columns]\n",
        "  other_columns = [col for col in data.columns if col not in tsne_features]\n",
        "  other_features = data[other_columns]\n",
        "\n",
        "  tsne = TSNE(n_components=2, perplexity=perplexity, learning_rate=learning_rate, n_iter=n_iter)\n",
        "  tsne_result = tsne.fit_transform(tsne_features)\n",
        "  tsne_df = pd.DataFrame(tsne_result, index = tsne_features.index, columns=['t-SNE Component 1', 't-SNE Component 2'])\n",
        "\n",
        "  temp_dataset = tsne_df.join(other_features, how='left')\n",
        "\n",
        "  # Create scatterplot using seaborn\n",
        "  scatterplot = sns.scatterplot(data=temp_dataset, x='t-SNE Component 1', y='t-SNE Component 2', alpha=alpha, s=size,\n",
        "                                hue=\"clusters\", palette='tab10', style='Error_Type')\n",
        "  scatterplot.set_title(title)\n",
        "  scatterplot.legend(loc='center left', bbox_to_anchor=(1.0, 0.5), ncol=1)\n",
        "\n",
        "  plt.savefig(fig_prefix+re.sub(' +', '', title)+'.png', bbox_inches='tight', pad_inches=0)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "XsHEidlPOsWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Means Clustering"
      ],
      "metadata": {
        "id": "ot8OI3PtOvXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hbac_kmeans(data, columns_to_use=[], error='errors',\n",
        "                min_splittable_cluster_prop = 0.05,\n",
        "                min_acceptable_cluster_prop = 0.03,\n",
        "                min_acceptable_error_diff = 0.01,\n",
        "                max_iter=300):\n",
        "    clus_model_kwargs = {\n",
        "        \"n_clusters\": 2,  # Number of clusters to form\n",
        "        \"init\": \"k-means++\",  # Centroids initialization method\n",
        "        \"n_init\": 10,  # Number of initializations\n",
        "        \"max_iter\": max_iter,  # Maximum iterations for a single run\n",
        "    }\n",
        "\n",
        "    min_splittable_cluster_size = round(min_splittable_cluster_prop * len(data))  # Minimum size of cluster to be split\n",
        "    min_acceptable_cluster_size = round(min_acceptable_cluster_prop * len(data))  # Minimum acceptable size of cluster after split\n",
        "\n",
        "    # Initialize loop's variables\n",
        "    data['clusters'] = 0\n",
        "    banned_clusters = []\n",
        "\n",
        "    #### CLUSTERING LOOP\n",
        "    for i in range(1, max_iter):\n",
        "      # Init temporary cluster\n",
        "      data['new_clusters'] = None\n",
        "\n",
        "      ### Select the cluster to split in 2\n",
        "      x = get_next_cluster(data, 'clusters', min_splittable_cluster_size, data['clusters'].unique(), banned_clusters)\n",
        "      if(x == -1):\n",
        "        break\n",
        "\n",
        "      candidate_cluster = data.copy(deep=True)\n",
        "      candidate_cluster = candidate_cluster.loc[candidate_cluster['clusters'] == x]\n",
        "\n",
        "      #### SPLIT IN 2 SUB-CLUSTERS\n",
        "      kmeans = KMeans(**clus_model_kwargs).fit(candidate_cluster[columns_to_use])\n",
        "      candidate_cluster['new_clusters'] = kmeans.labels_\n",
        "\n",
        "      # KEEP CLUSTER OR NOT\n",
        "      # ...are cluster size large enough?\n",
        "      l0 = len(candidate_cluster.loc[candidate_cluster['new_clusters'] == 0])\n",
        "      l1 = len(candidate_cluster.loc[candidate_cluster['new_clusters'] == 1])\n",
        "\n",
        "      if((l0 < min_acceptable_cluster_size) | (l1 < min_acceptable_cluster_size)):\n",
        "        #print('Bad split: too small')\n",
        "        banned_clusters.append(x)\n",
        "        continue\n",
        "\n",
        "      # ...is error rate difference large enough?\n",
        "      e0 = get_error_rate(candidate_cluster.loc[candidate_cluster['new_clusters'] == 0])\n",
        "      e1 = get_error_rate(candidate_cluster.loc[candidate_cluster['new_clusters'] == 1])\n",
        "\n",
        "      if(abs(e0 - e1) < min_acceptable_error_diff):\n",
        "        #print('Bad split: same error')\n",
        "        banned_clusters.append(x)\n",
        "        continue\n",
        "\n",
        "      ### Re-integrate to main data\n",
        "      data['new_clusters'] = candidate_cluster['new_clusters'].combine_first(data['new_clusters'])\n",
        "\n",
        "      # Make new Cluster IDs\n",
        "      new_id = data['clusters'].unique().max() + 1\n",
        "      data.loc[((data.clusters == x) & (data.new_clusters == 1)), 'clusters'] = new_id\n",
        "\n",
        "    #print('Max iterations reached:', i)\n",
        "    return data"
      ],
      "metadata": {
        "id": "tMIkBd8VOurn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SETUP EXPERIMENTS"
      ],
      "metadata": {
        "id": "_MXFx6AUP4Wy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare Data"
      ],
      "metadata": {
        "id": "CaUgZzHeP9ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v2_all = pd.read_csv('/content/drive/MyDrive/Mirthe_Supervision /Paper#2/Colab Notebooks/v2_all_pre-processed.csv')\n",
        "\n",
        "#split into TP/FN and TN/FP\n",
        "TPFN_data = subset_TP_FN(v2_all)\n",
        "TNFP_data = subset_TN_FP(v2_all)\n",
        "\n",
        "# Drop NA's\n",
        "TPFN_data = TPFN_data.dropna()\n",
        "TNFP_data = TNFP_data.dropna()"
      ],
      "metadata": {
        "id": "PxI5az1TP8Ka"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set experimental conditions"
      ],
      "metadata": {
        "id": "ghRId9HGQjne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### HBAC parameters\n",
        "min_splittable_cluster_prop = 0.05\n",
        "min_acceptable_cluster_prop = 0.05\n",
        "min_acceptable_error_diff = 0.005\n",
        "\n",
        "##### Make and name the sets of features to experiment with\n",
        "feature_set_name = []\n",
        "feature_set_descr = []\n",
        "feature_set = []\n",
        "\n",
        "######### BASELINE HBAC\n",
        "### Does adding SHAP help the clustering?\n",
        "# Baseline (Mitzal-Radheka)\n",
        "feature_set_name.append(f'+REG +SEN  -err     -shap')\n",
        "feature_set_descr.append('Baseline')\n",
        "feature_set.append(REG_scaled + DUMMY_scaled + SEN_scaled)\n",
        "\n",
        "# Baseline with Error (Selma)\n",
        "feature_set_name.append('+REG +SEN +ERR  -shap')\n",
        "feature_set_descr.append('Baseline with Error')\n",
        "feature_set.append(REG_scaled + DUMMY_scaled + SEN_scaled + ERROR_scaled)\n",
        "\n",
        "# Adding SHAP values to Baseline (Mirthe;)\n",
        "feature_set_name.append('+REG +SEN  -err    +SHAP')\n",
        "feature_set_descr.append('Baseline with SHAP')\n",
        "feature_set.append(REG_scaled + DUMMY_scaled + SEN_scaled + SHAP_REG_scaled + SHAP_DUMMY_scaled + SHAP_SEN_scaled)\n",
        "\n",
        "feature_set_name.append('+REG +SEN +ERR  +SHAP')\n",
        "feature_set_descr.append('Baseline with SHAP & Error')\n",
        "feature_set.append(REG_scaled + DUMMY_scaled + SEN_scaled + ERROR_scaled + SHAP_REG_scaled + SHAP_DUMMY_scaled + SHAP_SEN_scaled)\n",
        "\n",
        "\n",
        "############ SHAP-ONLY HBAC\n",
        "### Does SHAP alone allow to identify clusters?\n",
        "# Using only SHAP values\n",
        "feature_set_name.append('-reg    -sen    -err     +SHAP')\n",
        "feature_set_descr.append('SHAP only')\n",
        "feature_set.append(SHAP_REG_scaled + SHAP_DUMMY_scaled)\n",
        "\n",
        "feature_set_name.append('-reg    -sen    +ERR  +SHAP')\n",
        "feature_set_descr.append('SHAP only with Error')\n",
        "feature_set.append(SHAP_REG_scaled + SHAP_DUMMY_scaled + ERROR_scaled)\n",
        "\n",
        "\n",
        "############ ONLY SENSITIVE FEATURES\n",
        "### Do sensitive features alone allow to identify clusters?\n",
        "# Using only Sensitive features\n",
        "feature_set_name.append('-reg    +SEN  -err     -shap')\n",
        "feature_set_descr.append('Sensitive features only')\n",
        "feature_set.append(SEN_scaled)\n",
        "\n",
        "feature_set_name.append('-reg    +SEN +ERR   -shap')\n",
        "feature_set_descr.append('Sensitive features with Error')\n",
        "feature_set.append(SEN_scaled + ERROR_scaled)\n",
        "\n",
        "### Does adding SHAP help the clustering based on sensitive features?\n",
        "# Using Sensitive features with SHAP values\n",
        "feature_set_name.append('-reg    +SEN  -err     +SHAP_S')\n",
        "feature_set_descr.append('Sensitive features with SHAP')\n",
        "feature_set.append(SEN_scaled + SHAP_SEN_scaled)\n",
        "\n",
        "feature_set_name.append('-reg    +SEN +ERR  +SHAP_S')\n",
        "feature_set_descr.append('Sensitive features with SHAP & Error')\n",
        "feature_set.append(SEN_scaled + SHAP_SEN_scaled + ERROR_scaled)\n",
        "\n",
        "# Using only SHAP of Sensitive features\n",
        "feature_set_name.append('-reg    -sen    -err     +SHAP_S')\n",
        "feature_set_descr.append('Only SHAP of Sensitive features')\n",
        "feature_set.append(SHAP_SEN_scaled)\n",
        "\n",
        "feature_set_name.append('-reg    -sen    +ERR  +SHAP_S')\n",
        "feature_set_descr.append('Only SHAP of Sensitive features')\n",
        "feature_set.append(SHAP_SEN_scaled + ERROR_scaled)\n",
        "\n",
        "\n",
        "############ ONLY REGULAR FEATURES\n",
        "#conditons without sensitive to check how much it explains the results\n",
        "feature_set_name.append('+REG -sen    -err     -shap')\n",
        "feature_set_descr.append('REG Only')\n",
        "feature_set.append(REG_scaled)\n",
        "\n",
        "feature_set_name.append('+REG -sen    +ERR  -shap')\n",
        "feature_set_descr.append('REG & ERROR')\n",
        "feature_set.append(REG_scaled + ERROR_scaled)\n",
        "\n",
        "feature_set_name.append('+REG -sen    -err     +SHAP_R')\n",
        "feature_set_descr.append('REG & SHAP')\n",
        "feature_set.append(REG_scaled + SHAP_REG_scaled) # ERROR FIXED\n",
        "\n",
        "feature_set_name.append('+REG -sen    +ERR  +SHAP_R')\n",
        "feature_set_descr.append('REG, ERROR & SHAP')\n",
        "feature_set.append(REG_scaled + ERROR_scaled + SHAP_REG_scaled) # ERROR FIXED\n",
        "\n",
        "# Using only SHAP of Regular features\n",
        "feature_set_name.append('-reg    -sen    -err     +SHAP_R')\n",
        "feature_set_descr.append('Only SHAP of Regular features')\n",
        "feature_set.append(SHAP_REG_scaled)\n",
        "\n",
        "feature_set_name.append('-reg    -sen    +ERR  +SHAP_R')\n",
        "feature_set_descr.append('Only SHAP of Regular features + Error')\n",
        "feature_set.append(SHAP_REG_scaled + ERROR_scaled)\n",
        "\n",
        "exp_condition = pd.DataFrame({'feature_set_descr': feature_set_descr,\n",
        "                              'feature_set_name': feature_set_name,\n",
        "                              'feature_set': feature_set})\n",
        "exp_condition\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "xG1RKfVsQmP7",
        "outputId": "d98f2077-c13b-4362-ed27-e01699c510e3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        feature_set_descr                  feature_set_name  \\\n",
              "0                                Baseline         +REG +SEN  -err     -shap   \n",
              "1                     Baseline with Error             +REG +SEN +ERR  -shap   \n",
              "2                      Baseline with SHAP          +REG +SEN  -err    +SHAP   \n",
              "3              Baseline with SHAP & Error             +REG +SEN +ERR  +SHAP   \n",
              "4                               SHAP only    -reg    -sen    -err     +SHAP   \n",
              "5                    SHAP only with Error       -reg    -sen    +ERR  +SHAP   \n",
              "6                 Sensitive features only      -reg    +SEN  -err     -shap   \n",
              "7           Sensitive features with Error         -reg    +SEN +ERR   -shap   \n",
              "8            Sensitive features with SHAP    -reg    +SEN  -err     +SHAP_S   \n",
              "9    Sensitive features with SHAP & Error        -reg    +SEN +ERR  +SHAP_S   \n",
              "10        Only SHAP of Sensitive features  -reg    -sen    -err     +SHAP_S   \n",
              "11        Only SHAP of Sensitive features     -reg    -sen    +ERR  +SHAP_S   \n",
              "12                               REG Only       +REG -sen    -err     -shap   \n",
              "13                            REG & ERROR          +REG -sen    +ERR  -shap   \n",
              "14                             REG & SHAP     +REG -sen    -err     +SHAP_R   \n",
              "15                      REG, ERROR & SHAP        +REG -sen    +ERR  +SHAP_R   \n",
              "16          Only SHAP of Regular features  -reg    -sen    -err     +SHAP_R   \n",
              "17  Only SHAP of Regular features + Error     -reg    -sen    +ERR  +SHAP_R   \n",
              "\n",
              "                                          feature_set  \n",
              "0   [bank_branch_count_8w_scaled, device_os_scaled...  \n",
              "1   [bank_branch_count_8w_scaled, device_os_scaled...  \n",
              "2   [bank_branch_count_8w_scaled, device_os_scaled...  \n",
              "3   [bank_branch_count_8w_scaled, device_os_scaled...  \n",
              "4   [bank_branch_count_8w_shap_scaled, device_os_s...  \n",
              "5   [bank_branch_count_8w_shap_scaled, device_os_s...  \n",
              "6                [customer_age_scaled, income_scaled]  \n",
              "7   [customer_age_scaled, income_scaled, errors_sc...  \n",
              "8   [customer_age_scaled, income_scaled, customer_...  \n",
              "9   [customer_age_scaled, income_scaled, customer_...  \n",
              "10     [customer_age_shap_scaled, income_shap_scaled]  \n",
              "11  [customer_age_shap_scaled, income_shap_scaled,...  \n",
              "12  [bank_branch_count_8w_scaled, device_os_scaled...  \n",
              "13  [bank_branch_count_8w_scaled, device_os_scaled...  \n",
              "14  [bank_branch_count_8w_scaled, device_os_scaled...  \n",
              "15  [bank_branch_count_8w_scaled, device_os_scaled...  \n",
              "16  [bank_branch_count_8w_shap_scaled, device_os_s...  \n",
              "17  [bank_branch_count_8w_shap_scaled, device_os_s...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-abf2cf5f-9709-4b8c-b786-44825227d6b8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_set_descr</th>\n",
              "      <th>feature_set_name</th>\n",
              "      <th>feature_set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline</td>\n",
              "      <td>+REG +SEN  -err     -shap</td>\n",
              "      <td>[bank_branch_count_8w_scaled, device_os_scaled...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Baseline with Error</td>\n",
              "      <td>+REG +SEN +ERR  -shap</td>\n",
              "      <td>[bank_branch_count_8w_scaled, device_os_scaled...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Baseline with SHAP</td>\n",
              "      <td>+REG +SEN  -err    +SHAP</td>\n",
              "      <td>[bank_branch_count_8w_scaled, device_os_scaled...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Baseline with SHAP &amp; Error</td>\n",
              "      <td>+REG +SEN +ERR  +SHAP</td>\n",
              "      <td>[bank_branch_count_8w_scaled, device_os_scaled...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SHAP only</td>\n",
              "      <td>-reg    -sen    -err     +SHAP</td>\n",
              "      <td>[bank_branch_count_8w_shap_scaled, device_os_s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SHAP only with Error</td>\n",
              "      <td>-reg    -sen    +ERR  +SHAP</td>\n",
              "      <td>[bank_branch_count_8w_shap_scaled, device_os_s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Sensitive features only</td>\n",
              "      <td>-reg    +SEN  -err     -shap</td>\n",
              "      <td>[customer_age_scaled, income_scaled]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Sensitive features with Error</td>\n",
              "      <td>-reg    +SEN +ERR   -shap</td>\n",
              "      <td>[customer_age_scaled, income_scaled, errors_sc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Sensitive features with SHAP</td>\n",
              "      <td>-reg    +SEN  -err     +SHAP_S</td>\n",
              "      <td>[customer_age_scaled, income_scaled, customer_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Sensitive features with SHAP &amp; Error</td>\n",
              "      <td>-reg    +SEN +ERR  +SHAP_S</td>\n",
              "      <td>[customer_age_scaled, income_scaled, customer_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Only SHAP of Sensitive features</td>\n",
              "      <td>-reg    -sen    -err     +SHAP_S</td>\n",
              "      <td>[customer_age_shap_scaled, income_shap_scaled]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Only SHAP of Sensitive features</td>\n",
              "      <td>-reg    -sen    +ERR  +SHAP_S</td>\n",
              "      <td>[customer_age_shap_scaled, income_shap_scaled,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>REG Only</td>\n",
              "      <td>+REG -sen    -err     -shap</td>\n",
              "      <td>[bank_branch_count_8w_scaled, device_os_scaled...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>REG &amp; ERROR</td>\n",
              "      <td>+REG -sen    +ERR  -shap</td>\n",
              "      <td>[bank_branch_count_8w_scaled, device_os_scaled...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>REG &amp; SHAP</td>\n",
              "      <td>+REG -sen    -err     +SHAP_R</td>\n",
              "      <td>[bank_branch_count_8w_scaled, device_os_scaled...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>REG, ERROR &amp; SHAP</td>\n",
              "      <td>+REG -sen    +ERR  +SHAP_R</td>\n",
              "      <td>[bank_branch_count_8w_scaled, device_os_scaled...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Only SHAP of Regular features</td>\n",
              "      <td>-reg    -sen    -err     +SHAP_R</td>\n",
              "      <td>[bank_branch_count_8w_shap_scaled, device_os_s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Only SHAP of Regular features + Error</td>\n",
              "      <td>-reg    -sen    +ERR  +SHAP_R</td>\n",
              "      <td>[bank_branch_count_8w_shap_scaled, device_os_s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-abf2cf5f-9709-4b8c-b786-44825227d6b8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-abf2cf5f-9709-4b8c-b786-44825227d6b8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-abf2cf5f-9709-4b8c-b786-44825227d6b8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cf1d7d52-e68b-4331-9903-8484276c947c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cf1d7d52-e68b-4331-9903-8484276c947c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cf1d7d52-e68b-4331-9903-8484276c947c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_22863f31-76de-489c-9361-8b6f0d5e59f9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('exp_condition')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_22863f31-76de-489c-9361-8b6f0d5e59f9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('exp_condition');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "exp_condition",
              "summary": "{\n  \"name\": \"exp_condition\",\n  \"rows\": 18,\n  \"fields\": [\n    {\n      \"column\": \"feature_set_descr\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"Baseline\",\n          \"Baseline with Error\",\n          \"SHAP only with Error\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"feature_set_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"+REG +SEN  -err     -shap\",\n          \"+REG +SEN +ERR  -shap\",\n          \"-reg    +SEN  -err     +SHAP_S\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"feature_set\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TPFN RESULTS"
      ],
      "metadata": {
        "id": "GSeOiRdSTuRm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execute experiments"
      ],
      "metadata": {
        "id": "DPFyVTgsPtc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set global seed\n",
        "seed_value = 42\n",
        "np.random.seed(seed_value)\n",
        "random.seed(seed_value)\n",
        "\n",
        "results = {'cond_name': [],\n",
        "           'cond_descr': [],\n",
        "           'cond_res': [],\n",
        "           'cond_recap': []}\n",
        "\n",
        "for i in range(0, len(exp_condition)):\n",
        "    # Pass seed to ensure reproducibility\n",
        "    res = hbac_kmeans(TNFP_data.copy(deep=True),\n",
        "                      columns_to_use=exp_condition['feature_set'][i],\n",
        "                      error='errors',\n",
        "                      min_splittable_cluster_prop=min_splittable_cluster_prop,\n",
        "                      min_acceptable_cluster_prop=min_acceptable_cluster_prop,\n",
        "                      min_acceptable_error_diff=min_acceptable_error_diff,\n",
        "                      max_iter=100,\n",
        "                      random_state=seed_value)  # Assuming hbac_kmeans accepts random_state\n",
        "\n",
        "    recap = make_recap(res, exp_condition['feature_set'][i])\n",
        "\n",
        "    results['cond_name'].append(exp_condition['feature_set_name'][i])\n",
        "    results['cond_descr'].append(exp_condition['feature_set_descr'][i])\n",
        "    results['cond_res'].append(res)\n",
        "    results['cond_recap'].append(recap)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "UjgafyONPtI9",
        "outputId": "b02cf6c0-8e32-429c-bd07-fac1b61b53d5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'hbac_kmeans' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0342b9818404>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_condition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Pass seed to ensure reproducibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     res = hbac_kmeans(TNFP_data.copy(deep=True),\n\u001b[0m\u001b[1;32m     14\u001b[0m                       \u001b[0mcolumns_to_use\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexp_condition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feature_set'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                       \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'hbac_kmeans' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CHI-Square Tests TNFP data"
      ],
      "metadata": {
        "id": "iW8gJmKLT6CM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chi_res = make_chi_tests(results)\n",
        "chi_res_viz = chi_res.set_index('cond_name').drop('cond_descr', axis=1)\n",
        "chi_res_viz = round(chi_res_viz, 6)\n",
        "chi_res_viz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "XsYyy1jnT5dP",
        "outputId": "0e901985-9fa5-4589-a4c0-133ef0ae6a6b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [error, age, income]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-44ddf295-52e0-4aab-baff-8a0f5427d228\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>error</th>\n",
              "      <th>age</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cond_name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44ddf295-52e0-4aab-baff-8a0f5427d228')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-44ddf295-52e0-4aab-baff-8a0f5427d228 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-44ddf295-52e0-4aab-baff-8a0f5427d228');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_acc8a7ae-f0c1-434f-ba85-b1548e1ef95c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('chi_res_viz')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_acc8a7ae-f0c1-434f-ba85-b1548e1ef95c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('chi_res_viz');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "chi_res_viz",
              "summary": "{\n  \"name\": \"chi_res_viz\",\n  \"rows\": 0,\n  \"fields\": [\n    {\n      \"column\": \"cond_name\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"error\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "ax = sns.heatmap(chi_res_viz, annot=True, center=0,\n",
        "                cmap=sns.color_palette(\"vlag\", as_cmap=True), robust=False)\n",
        "ax.xaxis.tick_top()\n",
        "plt.yticks(rotation='horizontal')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "flLG1XfjUAz1",
        "outputId": "2cbf098b-2e35-48d7-c868-14557af9e46d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "zero-size array to reduction operation fmin which has no identity",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-c52071921b52>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m ax = sns.heatmap(chi_res_viz, annot=True, center=0,\n\u001b[0m\u001b[1;32m      3\u001b[0m                 cmap=sns.color_palette(\"vlag\", as_cmap=True), robust=False)\n\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_top\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'horizontal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/matrix.py\u001b[0m in \u001b[0;36mheatmap\u001b[0;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \"\"\"\n\u001b[1;32m    445\u001b[0m     \u001b[0;31m# Initialize the plotter object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m     plotter = _HeatMapper(data, vmin, vmax, cmap, center, robust, annot, fmt,\n\u001b[0m\u001b[1;32m    447\u001b[0m                           \u001b[0mannot_kws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbar_kws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticklabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                           yticklabels, mask)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/matrix.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;31m# Determine good default values for the colormapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         self._determine_cmap_params(plot_data, vmin, vmax,\n\u001b[0m\u001b[1;32m    164\u001b[0m                                     cmap, center, robust)\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/matrix.py\u001b[0m in \u001b[0;36m_determine_cmap_params\u001b[0;34m(self, plot_data, vmin, vmax, cmap, center, robust)\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0mvmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                 \u001b[0mvmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrobust\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/nanfunctions.py\u001b[0m in \u001b[0;36mnanmin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;31m# Fast, but not safe for subclasses of ndarray, or object arrays,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;31m# which do not implement isnan (gh-9009), or fmin correctly (gh-8975)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             warnings.warn(\"All-NaN slice encountered\", RuntimeWarning,\n",
            "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation fmin which has no identity"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ALL quality metrics TNFP data"
      ],
      "metadata": {
        "id": "rP8_6QDHUHgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_quali = recap_quali_metrics(chi_res, results, exp_condition)\n",
        "all_quali_viz = all_quali.set_index('cond_name').drop('cond_descr', axis=1)\n",
        "all_quali_viz = round(all_quali_viz, 6)\n",
        "# all_quali_viz"
      ],
      "metadata": {
        "id": "efxep25xUDZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(4,4))\n",
        "ax = sns.heatmap(all_quali_viz, annot=True, center=0, cbar=False,\n",
        "                cmap=sns.color_palette(\"vlag\", as_cmap=True), robust=True)\n",
        "ax.set(xlabel=\"\", ylabel=\"\")\n",
        "ax.xaxis.tick_top()\n",
        "ax.tick_params(axis='x', which='major', length=0)\n",
        "ax.tick_params(axis='y', which='major', pad=150, length=0)\n",
        "plt.yticks(ha='left')\n",
        "plt.savefig('TNFP_Kmeans.png', bbox_inches='tight', pad_inches=0)\n",
        "files.download('TNFP_Kmeans.png')\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "0ul4KVDEUFDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detailed TNFP results"
      ],
      "metadata": {
        "id": "Em40SmMGUO-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One-vs-All cluster comparison TNFP data"
      ],
      "metadata": {
        "id": "c5PT0mM7UV5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(exp_condition)):\n",
        "  print(i)\n",
        "  recap = results['cond_recap'][i].sort_values(by=['diff_vs_rest'], ascending=False)\n",
        "  recap['count'] = recap['count']/recap['count'].sum()\n",
        "  recap = recap.rename(columns={\"count\": \"size_prop\"})\n",
        "  recap = recap.drop(['n_error','c'], axis=1)\n",
        "\n",
        "  plt.figure(figsize=(10,4))\n",
        "  ax = sns.heatmap(recap, annot=True, center=0, cbar=False,\n",
        "                   cmap=sns.color_palette(\"vlag\", as_cmap=True), robust=True)\n",
        "  ax.set_title(re.sub(' +', ' ', results['cond_name'][i]))\n",
        "  ax.xaxis.tick_top()\n",
        "  ax.set(xlabel=\"\", ylabel=\"\")\n",
        "  ax.tick_params(axis='x', which='major', length=0)\n",
        "  ax.tick_params(axis='y', which='major', length=0)\n",
        "  ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='left', rotation_mode='anchor')\n",
        "  plt.yticks(rotation='horizontal')\n",
        "  plt.savefig('TNFP_Kmeans_'+re.sub(' +', '', results['cond_name'][i])+'.png', bbox_inches='tight', pad_inches=0)\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "LMexenbIURp-",
        "outputId": "620a082a-4410-4aab-b3ca-62850786b80f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-17-463331590dd4>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-463331590dd4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    One-vs-All cluster comparison TNFP data\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "t-SNE TNFP data"
      ],
      "metadata": {
        "id": "BlX-YOScUdpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(exp_condition)):\n",
        "  plt.figure(figsize=(10,7))\n",
        "  tsne_plot_wClusters(results['cond_res'][i], title = re.sub(' +', ' ', results['cond_name'][i]),\n",
        "                      alpha = 0.7, size = 50,\n",
        "          tsne_columns = REG_scaled + DUMMY_scaled + SHAP_REG_scaled + SHAP_DUMMY_scaled,\n",
        "          perplexity = 30, learning_rate = 200, n_iter = 250, fig_prefix='TNFP_Kmeans_tSNE_')"
      ],
      "metadata": {
        "id": "LPsn3n-zUf5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TPFN RESULTS"
      ],
      "metadata": {
        "id": "e1hRSai_Utwn"
      }
    }
  ]
}