{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMlmN0ZD7YmgFfYOuOaaLj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MDankloff/ClusterCompas/blob/main/BAFV2data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "7-kBpl4bJH9b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d17HlBJaIX6e",
        "outputId": "742e0e01-1e6e-4a8c-8876-e1488eb31bf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import lightgbm as lgbm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import yaml\n",
        "import glob\n",
        "import random\n",
        "import os\n",
        "import joblib\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, roc_auc_score\n",
        "from sklearn.utils import resample"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dask[dataframe]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr6GvrPBJrHd",
        "outputId": "ab23b085-cc0f-4f23-89dc-e3ba0ebd6f28"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.10/dist-packages (2024.10.0)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (3.1.0)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (24.2)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.5.0)\n",
            "Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2.2.2)\n",
            "Collecting dask-expr<1.2,>=1.1 (from dask[dataframe])\n",
            "  Downloading dask_expr-1.1.21-py3-none-any.whl.metadata (2.6 kB)\n",
            "INFO: pip is looking at multiple versions of dask-expr to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading dask_expr-1.1.20-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading dask_expr-1.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading dask_expr-1.1.18-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading dask_expr-1.1.16-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.10/dist-packages (from dask-expr<1.2,>=1.1->dask[dataframe]) (17.0.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask[dataframe]) (3.21.0)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2024.2)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.4.0->dask[dataframe]) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[dataframe]) (1.17.0)\n",
            "Downloading dask_expr-1.1.16-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dask-expr\n",
            "Successfully installed dask-expr-1.1.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "! cd '/content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4pLQWb0JbOa",
        "outputId": "10ece37b-c331-45b9-89ef-7e17a9fa5f37"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOAD DATA & MODEL"
      ],
      "metadata": {
        "id": "XJMqPwdAKX1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF/parquet data'\n",
        "\n",
        "extension = \"parquet\" #for smaller \"parquet\" depending on the downloaded file\n",
        "data_paths = glob.glob(f\"{base_path}/*.{extension}\")\n",
        "\n",
        "def read_dataset(path, ext = extension):\n",
        "    if ext == \"csv\":\n",
        "      return pd.read_csv(path)\n",
        "    elif ext == \"parquet\":\n",
        "      return pd.read_parquet(path)\n",
        "    else:\n",
        "      raise ValueError(f\"Unsupported file extension: {ext}\")\n",
        "\n",
        "# Extract variant name from the file path (without the extension)\n",
        "def get_variant(path):\n",
        "    return os.path.basename(path).split(\".\")[0]\n",
        "\n",
        "# Dictionary comprehension to read all CSV files into a dictionary of DataFrames\n",
        "dataframes = {\n",
        "    get_variant(path): read_dataset(path) for path in data_paths\n",
        "}\n",
        "print(f\"Loaded datasets: {list(dataframes.keys())}\")\n",
        "\n",
        "datasets_paths = {\n",
        "    \"Base\": base_path + \"/Base.parquet\", # sampled to best represent original dataset\n",
        "    \"Variant I\": base_path + \"/Variant I.parquet\", # higher group size disparity than base - reducing the size of the minority group from approx 20 - 10% of the dataset\n",
        "    \"Variant II\": base_path + \"/Variant II.parquet\", # higher prevalence disparity than base - one group has 5 x the fraud detection rate of the other while group sizes are equal\n",
        "    \"Variant III\": base_path + \"/Variant III.parquet\", # better separability for one of the groups -\n",
        "    \"Variant IV\": base_path + \"/Variant IV.parquet\", # higher prevalence disparity in train\n",
        "    \"Variant V\": base_path + \"/Variant V.parquet\", # better separability in train for one of the groups\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neIazZ_YKW4U",
        "outputId": "859e7693-9127-4179-983d-ff9b48647a89"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded datasets: ['Base', 'Variant I', 'Variant II', 'Variant III', 'Variant IV', 'Variant V']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load best light gbm model from variant 2"
      ],
      "metadata": {
        "id": "X1FRyv0BMCa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''# directory containing the model files\n",
        "model_dir = '/content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF/Best Model per Variant/Accuracy'\n",
        "\n",
        "# Get list of all model files in the directory\n",
        "model_files = glob.glob(os.path.join(model_dir, '*.pkl'))\n",
        "\n",
        "# Dictionary to store loaded models\n",
        "models = {}\n",
        "\n",
        "# Load all models from the directory and save them to the dictionary\n",
        "for model_file in model_files:\n",
        "    # Load the model\n",
        "    with open(model_file, 'rb') as f:\n",
        "        model = joblib.load(f)\n",
        "\n",
        "    # Extract the model name from the file path (without extension)\n",
        "    model_name = os.path.basename(model_file).split('.')[0]\n",
        "\n",
        "    # Add the model to the dictionary\n",
        "    models[model_name] = model\n",
        "\n",
        "    # Optional: Save the model back (though it seems redundant here)\n",
        "    save_path = os.path.join(model_dir, f'{model_name}.pkl')\n",
        "    joblib.dump(model, save_path)\n",
        "\n",
        "    print(f\"Model '{model_name}' loaded and saved to: {save_path}\")\n",
        "\n",
        "# Accessing the best model for variant 2\n",
        "modelv2 = models.get(\"model_Variant II_top_4\")\n",
        "\n",
        "print(modelv2)'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TPNV8ABKsLt",
        "outputId": "2d486a97-a4f1-48ef-b63e-0fe6a283764e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 'model_Variant II_top_4' loaded and saved to: /content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF/Best Model per Variant/Accuracy/model_Variant II_top_4.pkl\n",
            "Model 'model_Base_top_4' loaded and saved to: /content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF/Best Model per Variant/Accuracy/model_Base_top_4.pkl\n",
            "Model 'model_Variant III_top_0' loaded and saved to: /content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF/Best Model per Variant/Accuracy/model_Variant III_top_0.pkl\n",
            "Model 'model_Variant I_top_4' loaded and saved to: /content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF/Best Model per Variant/Accuracy/model_Variant I_top_4.pkl\n",
            "Model 'model_Variant V_top_0' loaded and saved to: /content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF/Best Model per Variant/Accuracy/model_Variant V_top_0.pkl\n",
            "Model 'model_Variant IV_top_6' loaded and saved to: /content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF/Best Model per Variant/Accuracy/model_Variant IV_top_6.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explore data"
      ],
      "metadata": {
        "id": "WX2IA38aMY6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#rename dataset variant 2 and create a copy\n",
        "v2 = dataframes[\"Variant II\"]\n",
        "v2_old = v2.copy()"
      ],
      "metadata": {
        "id": "_bSoNyKtMd1-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', 50) # Increase the maximum number of columns displayed in Pandas to 50\n",
        "pd.set_option('display.max_rows', 50)\n",
        "v2.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUpuRlBjMebe",
        "outputId": "dfee0cca-383e-419e-dfe9-e1aaa09ca98d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000000 entries, 0 to 999999\n",
            "Data columns (total 32 columns):\n",
            " #   Column                            Non-Null Count    Dtype  \n",
            "---  ------                            --------------    -----  \n",
            " 0   fraud_bool                        1000000 non-null  int64  \n",
            " 1   income                            1000000 non-null  float64\n",
            " 2   name_email_similarity             1000000 non-null  float64\n",
            " 3   prev_address_months_count         1000000 non-null  int64  \n",
            " 4   current_address_months_count      1000000 non-null  int64  \n",
            " 5   customer_age                      1000000 non-null  int64  \n",
            " 6   days_since_request                1000000 non-null  float64\n",
            " 7   intended_balcon_amount            1000000 non-null  float64\n",
            " 8   payment_type                      1000000 non-null  object \n",
            " 9   zip_count_4w                      1000000 non-null  int64  \n",
            " 10  velocity_6h                       1000000 non-null  float64\n",
            " 11  velocity_24h                      1000000 non-null  float64\n",
            " 12  velocity_4w                       1000000 non-null  float64\n",
            " 13  bank_branch_count_8w              1000000 non-null  int64  \n",
            " 14  date_of_birth_distinct_emails_4w  1000000 non-null  int64  \n",
            " 15  employment_status                 1000000 non-null  object \n",
            " 16  credit_risk_score                 1000000 non-null  int64  \n",
            " 17  email_is_free                     1000000 non-null  int64  \n",
            " 18  housing_status                    1000000 non-null  object \n",
            " 19  phone_home_valid                  1000000 non-null  int64  \n",
            " 20  phone_mobile_valid                1000000 non-null  int64  \n",
            " 21  bank_months_count                 1000000 non-null  int64  \n",
            " 22  has_other_cards                   1000000 non-null  int64  \n",
            " 23  proposed_credit_limit             1000000 non-null  float64\n",
            " 24  foreign_request                   1000000 non-null  int64  \n",
            " 25  source                            1000000 non-null  object \n",
            " 26  session_length_in_minutes         1000000 non-null  float64\n",
            " 27  device_os                         1000000 non-null  object \n",
            " 28  keep_alive_session                1000000 non-null  int64  \n",
            " 29  device_distinct_emails_8w         1000000 non-null  int64  \n",
            " 30  device_fraud_count                1000000 non-null  int64  \n",
            " 31  month                             1000000 non-null  int64  \n",
            "dtypes: float64(9), int64(18), object(5)\n",
            "memory usage: 244.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v2['payment_type'].unique() #remove because anonymized\n",
        "v2['days_since_request'].unique() #remove because unclear values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsqk1Jm3Qly0",
        "outputId": "75537b47-afbf-4a14-aecf-bd4a1cfa60ab"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.01673985, 0.01900183, 0.04706417, ..., 0.03555377, 0.02066269,\n",
              "       0.0074784 ])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(v2['days_since_request'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsTgORz1RPpN",
        "outputId": "bb0eb100-b3cd-4e3e-e597-c8d1ac8a39d3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0         0.016740\n",
            "1         0.019002\n",
            "2         0.047064\n",
            "3         0.008007\n",
            "4         2.513544\n",
            "            ...   \n",
            "999995    0.001835\n",
            "999996    0.023952\n",
            "999997    0.035554\n",
            "999998    0.020663\n",
            "999999    0.007478\n",
            "Name: days_since_request, Length: 1000000, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v2['source'].unique()\n",
        "v2['device_os'].unique()\n",
        "v2['keep_alive_session'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlhNYX2fRyMQ",
        "outputId": "98d7a4d1-a92a-48bf-a5b2-69732ba6c7f1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Master dataset"
      ],
      "metadata": {
        "id": "3FWW5CM7Mba0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#FEATURES\n",
        "META = ['clusters', 'new_clusters']\n",
        "ERROR = ['errors', 'TP', 'TN', 'FN', 'FP']\n",
        "REG = ['bank_branch_count_8w', 'credit_risk_score', 'source', 'device_os','month', 'session_length_in_minutes', 'email_is_free', 'proposed_credit_limit', 'name_email_similarity',\n",
        "      'zip_count_4w', 'date_of_birth_distinct_emails_4w',\n",
        "      'housing_status', 'phone_mobile_valid', 'bank_months_count', 'has_other_cards', 'foreign_request',\n",
        "      'device_distinct_emails']\n",
        "SEN = ['customer_age', 'income', 'employment_status'] #protected attributes in BAF paper\n",
        "DUMMY = ['']\n",
        "\n",
        "#FEATURES SCALED\n",
        "ERROR_scaled = ['errors_scaled']\n",
        "REG_scaled =\n",
        "SEN_scaled =\n",
        "\n",
        "#SHAP FEATURES\n",
        "SHAP_REG =\n",
        "SHAP_SEN =\n",
        "SHAP_DUMMY =\n",
        "\n",
        "#SHAP FEATURES SCALED\n",
        "SHAP_REG_scaled =\n",
        "SHAP_DUMMY_scaled =\n",
        "\n",
        "'''remove features = 'device_fraud_count', 'intended_balcon_amount', 'payment_type', 'days_since_request',\n",
        "'velocity_6h', 'velocity_24h', 'velocity_4w', 'keep_alive_session', 'prev_address_months_count', 'current_address_months_count', 'phone_home_valid', 'bank_months_count' '''"
      ],
      "metadata": {
        "id": "VMmJHJ07MqTu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}